{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's begin analysing the code by replicating the results corresponding to section 4.1.1 in the original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:\\\\Desktop\\\\Lipschitz_DSNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.Function_1D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the testing set\n",
    "X, y = generate_testing_set(lambda x: slope_1_flat(x, n=100, seed=100), n_points=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([1000, 1])\n",
      "X_test shape: torch.Size([4000, 1])\n",
      "y_train shape: torch.Size([1000, 1])\n",
      "y_test shape: torch.Size([4000, 1])\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note for me: for the time being,I am intentionally keeping the test size larger than the train size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training and testing dataset, now we need to load the model and train it. This would also allow you to understand the 1-Lipschitz constraint model well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the saved configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "file_config_training=\"D:\\Desktop\\Lipschitz_DSNN\\configs\\config_1d.json\"\n",
    "with open(file_config_training, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_fn_params': {'activation_type': 'linearspline',\n",
       "  'groupsort_groupsize': 5,\n",
       "  'prelu_init': -1,\n",
       "  'lipschitz_constrained': True,\n",
       "  'spline_init': 'relu',\n",
       "  'spline_range': 0.5,\n",
       "  'spline_scaling_coeff': True,\n",
       "  'spline_size': 101,\n",
       "  'lmbda': 1e-07},\n",
       " 'dataset': {'function_type': 'f1',\n",
       "  'number_knots': 9,\n",
       "  'testing_dataset_size': 10000,\n",
       "  'training_dataset_size': 1000},\n",
       " 'exp_name': 'test',\n",
       " 'log_dir': '1d_exps/ortho',\n",
       " 'net_params': {'bias': True,\n",
       "  'layer_sizes': [1, 10, 10, 10, 1],\n",
       "  'projection': 'orthonormalize',\n",
       "  'weight_initialization': 'He_uniform'},\n",
       " 'optimizer': {'lr_spline_coeffs': 5e-05,\n",
       "  'lr_spline_scaling_coeffs': 0.0005,\n",
       "  'lr_weights': 0.002},\n",
       " 'seed': 5,\n",
       " 'training_options': {'batch_size': 10,\n",
       "  'epochs': 1000,\n",
       "  'nbr_models': 25,\n",
       "  'num_workers': 1}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking the configurations for 1d example\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### let's first change and simplify some of the config params\n",
    "config['dataset']['training_dataset_size']=100\n",
    "config['dataset']['testing_dataset_size']=200\n",
    "\n",
    "config['training_options']['batch_size']=1\n",
    "config['training_options']['epochs']=2## let's train only for 2 epochs\n",
    "\n",
    "config['training_options']['nbr_models']=1\n",
    "config['net_params']['layer_sizes']=[1,10,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_fn_params': {'activation_type': 'linearspline',\n",
       "  'groupsort_groupsize': 5,\n",
       "  'prelu_init': -1,\n",
       "  'lipschitz_constrained': True,\n",
       "  'spline_init': 'relu',\n",
       "  'spline_range': 0.5,\n",
       "  'spline_scaling_coeff': True,\n",
       "  'spline_size': 101,\n",
       "  'lmbda': 1e-07},\n",
       " 'dataset': {'function_type': 'f1',\n",
       "  'number_knots': 9,\n",
       "  'testing_dataset_size': 200,\n",
       "  'training_dataset_size': 100},\n",
       " 'exp_name': 'test',\n",
       " 'log_dir': '1d_exps/ortho',\n",
       " 'net_params': {'bias': True,\n",
       "  'layer_sizes': [1, 10, 1],\n",
       "  'projection': 'orthonormalize',\n",
       "  'weight_initialization': 'He_uniform'},\n",
       " 'optimizer': {'lr_spline_coeffs': 5e-05,\n",
       "  'lr_spline_scaling_coeffs': 0.0005,\n",
       "  'lr_weights': 0.002},\n",
       " 'seed': 5,\n",
       " 'training_options': {'batch_size': 1,\n",
       "  'epochs': 2,\n",
       "  'nbr_models': 1,\n",
       "  'num_workers': 1}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.62.2-cp38-cp38-win_amd64.whl (3.8 MB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in d:\\anaconda_neel\\lib\\site-packages (from tensorboard) (1.21.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\anaconda_neel\\lib\\site-packages (from tensorboard) (1.4.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda_neel\\lib\\site-packages (from tensorboard) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\anaconda_neel\\lib\\site-packages (from tensorboard) (65.7.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda_neel\\lib\\site-packages (from tensorboard) (1.0.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in d:\\anaconda_neel\\lib\\site-packages (from tensorboard) (0.36.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in d:\\anaconda_neel\\lib\\site-packages (from tensorboard) (4.25.3)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda_neel\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda_neel\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.4.1)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda_neel\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda_neel\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.18)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda_neel\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda_neel\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, requests-oauthlib, importlib-metadata, google-auth, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, tensorboard\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed google-auth-2.29.0 google-auth-oauthlib-1.0.0 grpcio-1.62.2 importlib-metadata-7.1.0 markdown-3.6 oauthlib-3.2.2 pyasn1-0.6.0 pyasn1-modules-0.4.0 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.14.0 tensorboard-data-server-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### let's load the trainer\n",
    "from utils import trainer_1d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the dataloaders\n",
      "Building the model(s)\n",
      "Number of models :  1\n",
      "Number of parameters in the model(s):  1051\n",
      "SimpleFC(\n",
      "  (layers): Sequential(\n",
      "    (0): LipschitzLinear(in_features=1, out_features=10, bias=True)\n",
      "    (1): LinearSpline(mode=fc, num_activations=10, init=relu, size=101, grid=0.010, lipschitz_constrained=True.)\n",
      "    (2): LipschitzLinear(in_features=10, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### instantiating the trainer\n",
    "train_1d_ae= trainer_1d.Trainer1D(config=config, seed=1, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SimpleFC(\n",
       "   (layers): Sequential(\n",
       "     (0): LipschitzLinear(in_features=1, out_features=10, bias=True)\n",
       "     (1): LinearSpline(mode=fc, num_activations=10, init=relu, size=101, grid=0.010, lipschitz_constrained=True.)\n",
       "     (2): LipschitzLinear(in_features=10, out_features=1, bias=True)\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now I need to print the model\n",
    "train_1d_ae.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object BaseModel.modules_linearspline at 0x000002729F765120>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1d_ae.models[0].modules_linearspline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T (0) | TotalLoss 0.06070914 |: 100%|████████████████████████████████████████████████████████████████| 100/100 [00:21<00:00,  4.72it/s]\n",
      "T (1) | TotalLoss 0.00760458 |: 100%|████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.82it/s]\n",
      "T (2) | TotalLoss 0.02052213 |: 100%|████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving a checkpoint:\n"
     ]
    }
   ],
   "source": [
    "### let's now train the model and in the process investigate what exactly is happening in the linear spline function\n",
    "train_1d_ae.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.002\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " \n",
       " Parameter Group 1\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 5e-05\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " \n",
       " Parameter Group 2\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.0005\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " )]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1d_ae.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['activation_fn_params']['lipschitz_constrained']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1d_ae.models[0].using_splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object BaseModel.modules_linearspline at 0x000002729F6BA2E0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1d_ae.models[0].modules_linearspline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleFC(\n",
       "  (layers): Sequential(\n",
       "    (0): LipschitzLinear(in_features=1, out_features=10, bias=True)\n",
       "    (1): LinearSpline(mode=fc, num_activations=10, init=relu, size=101, grid=0.010, lipschitz_constrained=True.)\n",
       "    (2): LipschitzLinear(in_features=10, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1d_ae.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, module in enumerate(train_1d_ae.models[0].modules_linearspline):\n",
    "                    num_act = module.num_activations\n",
    "                    size = module.size\n",
    "                    grid = module.grid\n",
    "                    coeffs = module.coefficients_vect.view(num_act, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5000e-05,  7.0366e-06,  1.1079e-05,  ...,  4.8025e-01,\n",
       "          4.9135e-01,  4.9865e-01],\n",
       "        [-1.4175e-05,  1.6300e-05, -1.4666e-05,  ...,  4.7969e-01,\n",
       "          4.9007e-01,  5.0029e-01],\n",
       "        [ 3.2881e-03, -3.3205e-03, -2.7684e-03,  ...,  4.8040e-01,\n",
       "          4.8986e-01,  5.0034e-01],\n",
       "        ...,\n",
       "        [-5.2165e-06,  4.3071e-06, -5.2331e-06,  ...,  4.8048e-01,\n",
       "          4.8965e-01,  5.0030e-01],\n",
       "        [-1.9703e-06,  2.0825e-06,  8.7813e-06,  ...,  4.7981e-01,\n",
       "          4.8974e-01,  5.0024e-01],\n",
       "        [-1.5425e-03,  1.5138e-03,  8.3034e-04,  ...,  4.8042e-01,\n",
       "          4.8968e-01,  5.0042e-01]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_normalization(cs, T):\n",
    "    lipschitz = torch.max(torch.abs(cs[:, 1:] - cs[:,:-1]), dim=1)[0]\n",
    "    print(\"lipschitz is:\", lipschitz)\n",
    "    new_cs = T * torch.div(cs.T, lipschitz).T\n",
    "\n",
    "    return new_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 101]), 10, 101, tensor([0.0100]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.shape, num_act, size, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lipschitz is: tensor([0.0115, 0.0195, 0.0108, 0.0155, 0.0109, 0.0216, 0.0116, 0.0109, 0.0115,\n",
      "        0.0110], grad_fn=<MaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1660e-05,  6.0965e-06,  9.5985e-06,  ...,  4.1609e-01,\n",
       "          4.2571e-01,  4.3203e-01],\n",
       "        [-7.2793e-06,  8.3708e-06, -7.5314e-06,  ...,  2.4634e-01,\n",
       "          2.5167e-01,  2.5692e-01],\n",
       "        [ 3.0498e-03, -3.0798e-03, -2.5678e-03,  ...,  4.4558e-01,\n",
       "          4.5435e-01,  4.6408e-01],\n",
       "        ...,\n",
       "        [-4.7643e-06,  3.9338e-06, -4.7795e-06,  ...,  4.3883e-01,\n",
       "          4.4721e-01,  4.5694e-01],\n",
       "        [-1.7163e-06,  1.8140e-06,  7.6493e-06,  ...,  4.1795e-01,\n",
       "          4.2661e-01,  4.3575e-01],\n",
       "        [-1.4078e-03,  1.3817e-03,  7.5786e-04,  ...,  4.3849e-01,\n",
       "          4.4694e-01,  4.5674e-01]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope_normalization(coeffs, grid.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.002\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " \n",
       " Parameter Group 1\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 5e-05\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " \n",
       " Parameter Group 2\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.0005\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " )]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1d_ae.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now I need to understand the set_optimization steo because it contains things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleFC(\n",
       "  (layers): Sequential(\n",
       "    (0): LipschitzLinear(in_features=1, out_features=10, bias=True)\n",
       "    (1): LinearSpline(mode=fc, num_activations=10, init=relu, size=101, grid=0.010, lipschitz_constrained=True.)\n",
       "    (2): LipschitzLinear(in_features=10, out_features=10, bias=True)\n",
       "    (3): LinearSpline(mode=fc, num_activations=10, init=relu, size=101, grid=0.010, lipschitz_constrained=True.)\n",
       "    (4): LipschitzLinear(in_features=10, out_features=10, bias=True)\n",
       "    (5): LinearSpline(mode=fc, num_activations=10, init=relu, size=101, grid=0.010, lipschitz_constrained=True.)\n",
       "    (6): LipschitzLinear(in_features=10, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### let's look into LinearSpline class and see how it works\n",
    "\n",
    "train_1d_ae.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_fn_params': {'activation_type': 'linearspline',\n",
       "  'groupsort_groupsize': 5,\n",
       "  'prelu_init': -1,\n",
       "  'lipschitz_constrained': True,\n",
       "  'spline_init': 'relu',\n",
       "  'spline_range': 0.5,\n",
       "  'spline_scaling_coeff': True,\n",
       "  'spline_size': 101,\n",
       "  'lmbda': 1e-07},\n",
       " 'dataset': {'function_type': 'f1',\n",
       "  'number_knots': 9,\n",
       "  'testing_dataset_size': 200,\n",
       "  'training_dataset_size': 100},\n",
       " 'exp_name': 'test',\n",
       " 'log_dir': '1d_exps/ortho',\n",
       " 'net_params': {'bias': True,\n",
       "  'layer_sizes': [1, 10, 1],\n",
       "  'projection': 'orthonormalize',\n",
       "  'weight_initialization': 'He_uniform'},\n",
       " 'optimizer': {'lr_spline_coeffs': 5e-05,\n",
       "  'lr_spline_scaling_coeffs': 0.0005,\n",
       "  'lr_weights': 0.002},\n",
       " 'seed': 5,\n",
       " 'training_options': {'batch_size': 1,\n",
       "  'epochs': 2,\n",
       "  'nbr_models': 1,\n",
       "  'num_workers': 1}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### go to pdf page number 11. they  have mentioned that they \n",
    "### and the LLS was\n",
    "# initialized as ReLU and had a range of [−0.5, 0.5], \n",
    "# 100 linear regions, and λ = 10−7\n",
    "# for the\n",
    "# TV(2) regularization.\n",
    "config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_arange is:\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "zero_knot indices:\n",
      "tensor([ 50, 151, 252, 353, 454, 555, 656, 757, 858, 959])\n"
     ]
    }
   ],
   "source": [
    "act_arange=torch.arange(0,10)\n",
    "print(\"act_arange is:\"); print(act_arange)\n",
    "zero_knot_indexes= (act_arange * 101 + (101 // 2))\n",
    "print(\"zero_knot indices:\"); print(zero_knot_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = 2* 0.5/(101-1)# range is 0.5\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 100., -200.,  100.]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1, -2, 1]).view(1, 1, 3).div(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5000, -0.4900, -0.4800, -0.4700, -0.4600, -0.4500, -0.4400, -0.4300,\n",
       "        -0.4200, -0.4100, -0.4000, -0.3900, -0.3800, -0.3700, -0.3600, -0.3500,\n",
       "        -0.3400, -0.3300, -0.3200, -0.3100, -0.3000, -0.2900, -0.2800, -0.2700,\n",
       "        -0.2600, -0.2500, -0.2400, -0.2300, -0.2200, -0.2100, -0.2000, -0.1900,\n",
       "        -0.1800, -0.1700, -0.1600, -0.1500, -0.1400, -0.1300, -0.1200, -0.1100,\n",
       "        -0.1000, -0.0900, -0.0800, -0.0700, -0.0600, -0.0500, -0.0400, -0.0300,\n",
       "        -0.0200, -0.0100,  0.0000,  0.0100,  0.0200,  0.0300,  0.0400,  0.0500,\n",
       "         0.0600,  0.0700,  0.0800,  0.0900,  0.1000,  0.1100,  0.1200,  0.1300,\n",
       "         0.1400,  0.1500,  0.1600,  0.1700,  0.1800,  0.1900,  0.2000,  0.2100,\n",
       "         0.2200,  0.2300,  0.2400,  0.2500,  0.2600,  0.2700,  0.2800,  0.2900,\n",
       "         0.3000,  0.3100,  0.3200,  0.3300,  0.3400,  0.3500,  0.3600,  0.3700,\n",
       "         0.3800,  0.3900,  0.4000,  0.4100,  0.4200,  0.4300,  0.4400,  0.4500,\n",
       "         0.4600,  0.4700,  0.4800,  0.4900,  0.5000])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(-0.5,0.5,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tensor=torch.linspace(-0.5,0.5,4).expand((6,4))\n",
    "grid_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tensor[::2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tensor[1::2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5000,  0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [ 0.5000,  0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [ 0.5000,  0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = torch.zeros(grid_tensor.shape)\n",
    "coefficients[::2, :] = (grid_tensor[::2, :]).abs()\n",
    "coefficients[1::2, :] = grid_tensor[1::2, :]\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5000,  0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [ 0.5000,  0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000],\n",
       "        [ 0.5000,  0.1667,  0.1667,  0.5000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5000,  0.1667,  0.1667,  0.5000, -0.5000, -0.1667,  0.1667,  0.5000,\n",
       "         0.5000,  0.1667,  0.1667,  0.5000, -0.5000, -0.1667,  0.1667,  0.5000,\n",
       "         0.5000,  0.1667,  0.1667,  0.5000, -0.5000, -0.1667,  0.1667,  0.5000])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients.contiguous().view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "check=torch.Tensor([[1,2,3,4],\n",
    "        [5,6,7,8],\n",
    "        [9,10,11,12],\n",
    "        [13,14,15,16],\n",
    "        [17,18,19,20],\n",
    "        [-0.5000, -0.1667,  0.1667,  0.5000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 9., 10., 11., 12.],\n",
       "        [17., 18., 19., 20.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[::2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0000,  6.0000,  7.0000,  8.0000],\n",
       "        [13.0000, 14.0000, 15.0000, 16.0000],\n",
       "        [-0.5000, -0.1667,  0.1667,  0.5000]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[1::2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import spline_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activations.linearspline import LinearSpline\n",
    "\n",
    "def get_spline_coefficients(model):\n",
    "    coeffs_list = []\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, LinearSpline):\n",
    "            coeffs_list.append(module.coefficients_vect)\n",
    "    return coeffs_list\n",
    "    \n",
    "def get_spline_scaling_coeffs(model):\n",
    "    coeffs_list = []\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, LinearSpline):\n",
    "            coeffs_list.append(module.scaling_coeffs_vect)\n",
    "    return coeffs_list\n",
    "\n",
    "def get_no_spline_coefficients(model):\n",
    "    coeffs_list = set(model.parameters())\n",
    "    coeffs_list = coeffs_list - set(get_spline_coefficients(model)) - set(get_spline_scaling_coeffs(model))\n",
    "    coeffs_list = list(coeffs_list)\n",
    "    return coeffs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.7653],\n",
       "         [ 0.1386],\n",
       "         [ 0.8019],\n",
       "         [ 0.3225],\n",
       "         [ 0.1878],\n",
       "         [ 0.5325],\n",
       "         [-0.8397],\n",
       "         [ 0.0776],\n",
       "         [-0.0912],\n",
       "         [-0.5753]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2756], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.9200,  0.2306, -0.5924,  0.2930, -0.7203,  0.1466,  0.1552,  0.9365,\n",
       "          0.7303, -0.6240], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.7137e-01,  5.5110e-02, -2.5477e-01,  2.6344e-05, -1.8383e-01,\n",
       "           2.8225e-01, -3.1604e-01,  1.6083e-01, -1.7860e-01, -2.4105e-01]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_no_spline_coefficients(train_1d_ae.models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([2.5000e-05, 7.0366e-06, 1.1079e-05,  ..., 4.8042e-01, 4.8968e-01,\n",
       "         5.0042e-01], requires_grad=True)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spline_coefficients(train_1d_ae.models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[0.9934]],\n",
       " \n",
       "          [[1.0157]],\n",
       " \n",
       "          [[1.0464]],\n",
       " \n",
       "          [[0.9979]],\n",
       " \n",
       "          [[0.9993]],\n",
       " \n",
       "          [[0.9702]],\n",
       " \n",
       "          [[0.9858]],\n",
       " \n",
       "          [[0.9990]],\n",
       " \n",
       "          [[0.9984]],\n",
       " \n",
       "          [[1.0237]]]], requires_grad=True)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spline_scaling_coeffs(train_1d_ae.models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's understand the forward function of linearspline activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([5, 10])\n",
      "Reshaped tensor shape: torch.Size([5, 10, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class DeepSplineActivation:\n",
    "    def __init__(self, mode):\n",
    "        self.mode = mode\n",
    "\n",
    "    def reshape_forward(self, x):\n",
    "        \"\"\"\n",
    "        Reshape inputs for deepspline activation forward pass, depending on\n",
    "        mode ('conv' or 'fc').\n",
    "        \"\"\"\n",
    "        input_size = x.size()\n",
    "        if self.mode == 'fc':\n",
    "            if len(input_size) == 2:\n",
    "                # one activation per conv channel\n",
    "                # transform to 4D size (N, num_units=num_activations, 1, 1)\n",
    "                x = x.view(*input_size, 1, 1)\n",
    "            else:\n",
    "                raise ValueError(f'input size is {len(input_size)}D but should be 2D')\n",
    "        else:\n",
    "            assert len(input_size) == 4, 'input to activation should be 4D (N, C, H, W) if mode=\"conv\".'\n",
    "\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "# Create an instance of DeepSplineActivation\n",
    "activation = DeepSplineActivation(mode='fc')\n",
    "\n",
    "# Create a tensor with size (batch_size, num_features)\n",
    "x = torch.randn(5, 10)\n",
    "\n",
    "# Reshape the tensor using reshape_forward\n",
    "reshaped_x = activation.reshape_forward(x)\n",
    "\n",
    "# Print the original and reshaped tensor\n",
    "print(\"Original tensor shape:\", x.shape)\n",
    "print(\"Reshaped tensor shape:\", reshaped_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([5, 3, 32, 32])\n",
      "Reshaped tensor shape: torch.Size([5, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "activation = DeepSplineActivation(mode='conv')\n",
    "\n",
    "# Create a tensor with size (batch_size, channels, height, width)\n",
    "x = torch.randn(5, 3, 32, 32)\n",
    "\n",
    "# Reshape the tensor using reshape_forward\n",
    "reshaped_x = activation.reshape_forward(x)\n",
    "\n",
    "# Print the original and reshaped tensor shapes\n",
    "print(\"Original tensor shape:\", x.shape)\n",
    "print(\"Reshaped tensor shape:\", reshaped_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial coefficients: tensor([[-2.3356,  2.4861, -1.7046,  0.7492]])\n",
      "new slopes are: tensor([[ 1., -1.,  1.]])\n",
      "new cs cumsum first term are: tensor([[0., 1., 0., 1.]])\n",
      "new_cs-cs: tensor([[ 2.3356, -1.4861,  1.7046,  0.2508]])\n",
      "mean operation: tensor([[-0.7012]])\n",
      "coefficients now: tensor([[-0.7012,  0.2988, -0.7012,  0.2988]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(-0.2012), tensor(-0.2012))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def slope_clipping(cs, T):\n",
    "    device = cs.device\n",
    "    n = cs.shape[1]\n",
    "    new_slopes = torch.clamp(cs[:,1:] - cs[:,:-1], -T, T)### this is the operation clipping_{T} (D c) (eqn 12 and 13)\n",
    "    print(f\"new slopes are: {new_slopes}\")\n",
    "    new_cs = torch.zeros(cs.shape, device=device)\n",
    "    new_cs[:,1:] = torch.cumsum(new_slopes, dim=1)\n",
    "    print(f\"new cs cumsum first term are: {new_cs}\")\n",
    "    print(f\"new_cs-cs: {new_cs-cs}\")\n",
    "    print(f\"mean operation: {torch.mean(cs - new_cs, dim=1).unsqueeze(1)}\")\n",
    "    new_cs = new_cs + torch.mean(cs - new_cs, dim=1).unsqueeze(1)\n",
    "    return new_cs\n",
    "\n",
    "\n",
    "cs= torch.randn(size=(1,4))\n",
    "print(f\"initial coefficients: {cs}\")\n",
    "T=1\n",
    "check= slope_clipping(cs,T)\n",
    "print(f\"coefficients now: {check}\")\n",
    "\n",
    "torch.mean(cs), torch.mean(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_forward_linear_spline(x, coefficients_vect, grid, size, even):\n",
    "\n",
    "    # The value of the spline at any x is a combination \n",
    "    # of at most two coefficients\n",
    "    max_range = (grid.item() * (size // 2 - 1))\n",
    "    if even:\n",
    "        x = x - grid / 2\n",
    "        max_range = (grid.item() * (size // 2 - 2))\n",
    "    x_clamped = x.clamp(min=-(grid.item() * (size // 2)), max=max_range)\n",
    "    print(\"clamped x is:\",x_clamped)\n",
    "\n",
    "    floored_x = torch.floor(x_clamped / grid)  #left coefficient\n",
    "    print(\"floored x is:\",floored_x)\n",
    "    #fracs = x_clamped / grid - floored_x\n",
    "    fracs = x / grid - floored_x  # distance to left coefficient\n",
    "    print(\"frac is (dist to the left coefs):\",fracs)\n",
    "    # This gives the indexes (in coefficients_vect) of the left\n",
    "    # coefficients\n",
    "    # indexes = (zero_knot_indexes.view(1, -1, 1, 1) + floored_x).long()\n",
    "    # # Only two B-spline basis functions are required to compute the output\n",
    "    # # (through linear interpolation) for each input in the B-spline range.\n",
    "    # activation_output = coefficients_vect[indexes + 1] * fracs + \\\n",
    "    #     coefficients_vect[indexes] * (1 - fracs)\n",
    "    # if even:\n",
    "    #     activation_output = activation_output + grid / 2\n",
    "\n",
    "    # ctx.save_for_backward(fracs, coefficients_vect, indexes, grid)\n",
    "    #return activation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor is: tensor([-10.5000,  -1.5000,   2.0000,   2.5000,   2.4000, -11.5000])\n",
      "clamped x is: tensor([-4.0000, -1.5000,  2.0000,  2.5000,  2.4000, -4.0000])\n",
      "floored x is: tensor([-4., -2.,  2.,  2.,  2., -4.])\n",
      "frac is (dist to the left coefs): tensor([-6.5000,  0.5000,  0.0000,  0.5000,  0.4000, -7.5000])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([-10.5,-1.5,2,2.5,2.4,-11.5])\n",
    "print(f\"original tensor is: {x}\")\n",
    "grid=torch.tensor([1])\n",
    "size=9\n",
    "coefficients=torch.randn(9)\n",
    "checking_forward_linear_spline(x,coefficients,grid,size,even=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_coeffs(init, grid_tensor, grid, size):\n",
    "        \"\"\"The coefficients are initialized with the value of the activation\n",
    "        # at each knot (c[k] = f[k], since B1 splines are interpolators).\"\"\"\n",
    "        \n",
    "        if init == 'identity':\n",
    "            coefficients = grid_tensor\n",
    "        elif init == 'zero':\n",
    "            coefficients = torch.zeros(grid_tensor.shape)\n",
    "        elif init == 'relu':\n",
    "            coefficients = F.relu(grid_tensor)\n",
    "        elif init == 'absolute_value':\n",
    "            coefficients = torch.abs(grid_tensor)\n",
    "            \n",
    "        elif init == 'maxmin':\n",
    "            # initalize half of the activations with the absolute and the other half with the \n",
    "            # identity. This is similar to maxmin because max(x1, x2) = (x1 + x2)/2 + |x1 - x2|/2 \n",
    "            # and min(x1, x2) = (x1 + x2)/2 - |x1 - x2|/2\n",
    "            coefficients = torch.zeros(grid_tensor.shape)\n",
    "            coefficients[::2, :] = (grid_tensor[::2, :]).abs()\n",
    "            coefficients[1::2, :] = grid_tensor[1::2, :]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('init should be in [identity, relu, absolute_value, maxmin, max_tv].')\n",
    "        \n",
    "        return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0000, -2.2500, -1.5000, -0.7500,  0.0000,  0.7500,  1.5000,  2.2500,\n",
      "          3.0000]])\n"
     ]
    }
   ],
   "source": [
    "grid_tensor = torch.linspace(-3,3,9).expand((1,9))\n",
    "print(grid_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7500, 1.5000, 2.2500, 3.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients= initialize_coeffs(init=\"relu\",\n",
    "                                grid_tensor=grid_tensor,\n",
    "                                grid=1,\n",
    "                                size=9)\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsqueezed_coeff:  tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7500, 1.5000, 2.2500,\n",
      "          3.0000]]])\n",
      "shape of the unsqueezed_coeff: torch.Size([1, 1, 9])\n"
     ]
    }
   ],
   "source": [
    "unsqueezed_coeff=coefficients.unsqueeze(1)\n",
    "print(\"unsqueezed_coeff: \", unsqueezed_coeff)\n",
    "print(f\"shape of the unsqueezed_coeff: {unsqueezed_coeff.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D2 filter is: tensor([[[ 1., -2.,  1.]]]) with shape torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "grid=1\n",
    "d2_filter=torch.tensor([1, -2, 1]).view(1, 1, 3).div(grid)\n",
    "print(f\"D2 filter is: {d2_filter} with shape {d2_filter.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.7500, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.conv1d(unsqueezed_coeff, d2_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I understand the code now, I now need to now run some test cases and then check how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. classification task with some toy adversarial example I believe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing torch.searchsorted function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices returned by searchsorted: tensor([4])\n",
      "Value 12 would be inserted at index 4, between 8 and 16 if index < 5.\n"
     ]
    }
   ],
   "source": [
    "# Create a sorted tensor with unequal distances\n",
    "sorted_tensor = torch.tensor([-1,2,4,8,16])\n",
    "\n",
    "# Values we want to search for\n",
    "values = torch.tensor([12])\n",
    "\n",
    "# Use searchsorted to find the indices\n",
    "indices = torch.searchsorted(sorted_tensor, values)\n",
    "\n",
    "# Output the results\n",
    "print(\"Indices returned by searchsorted:\", indices)\n",
    "\n",
    "# Demonstrate the insertion\n",
    "for value, index in zip(values, indices):\n",
    "    if index == 0:\n",
    "        print(f\"Value {value} would be inserted at the start of the tensor (index {index}).\")\n",
    "    elif index == len(sorted_tensor):\n",
    "        print(f\"Value {value} would be inserted at the end of the tensor (index {index}).\")\n",
    "    else:\n",
    "        print(f\"Value {value} would be inserted at index {index}, between {sorted_tensor[index - 1]} and {sorted_tensor[index]} if index < {len(sorted_tensor)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.floor(torch.Tensor([3])/torch.Tensor([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
